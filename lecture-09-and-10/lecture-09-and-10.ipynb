{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7XYFHcfyrBS"
      },
      "source": [
        "# Data Manipulation with Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFjRkeITyrBV"
      },
      "source": [
        "In [Part 2](02.00-Introduction-to-NumPy.ipynb), we dove into detail on NumPy and its `ndarray` object, which enables efficient storage and manipulation of dense typed arrays in Python.\n",
        "Here we'll build on this knowledge by looking in depth at the data structures provided by the Pandas library.\n",
        "Pandas is a newer package built on top of NumPy that provides an efficient implementation of a `DataFrame`.\n",
        "``DataFrame``s are essentially multidimensional arrays with attached row and column labels, often with heterogeneous types and/or missing data.\n",
        "As well as offering a convenient storage interface for labeled data, Pandas implements a number of powerful data operations familiar to users of both database frameworks and spreadsheet programs.\n",
        "\n",
        "As we've seen, NumPy's `ndarray` data structure provides essential features for the type of clean, well-organized data typically seen in numerical computing tasks.\n",
        "While it serves this purpose very well, its limitations become clear when we need more flexibility (e.g., attaching labels to data, working with missing data, etc.) and when attempting operations that do not map well to element-wise broadcasting (e.g., groupings, pivots, etc.), each of which is an important piece of analyzing the less structured data available in many forms in the world around us.\n",
        "Pandas, and in particular its `Series` and `DataFrame` objects, builds on the NumPy array structure and provides efficient access to these sorts of \"data munging\" tasks that occupy much of a data scientist's time.\n",
        "\n",
        "In this part of the book, we will focus on the mechanics of using `Series`, `DataFrame`, and related structures effectively.\n",
        "We will use examples drawn from real datasets where appropriate, but these examples are not necessarily the focus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhN23hxoyrBZ"
      },
      "source": [
        "This import convention will be used throughout the remainder of this book."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "48ySIHhTzJDK",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikCvUDnezJDL"
      },
      "source": [
        "## The Pandas Series Object\n",
        "\n",
        "A Pandas `Series` is a one-dimensional array of indexed data.\n",
        "It can be created from a list or array as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "olg20L94zJDM",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "83feeb8d-19cc-489a-fb3a-bd6701f7ad6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0.25\n",
              "1    0.50\n",
              "2    0.75\n",
              "3    1.00\n",
              "dtype: float64"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.Series([0.25, 0.5, 0.75, 1.0])\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNVTfyOnzJDN"
      },
      "source": [
        "The `Series` combines a sequence of values with an explicit sequence of indices, which we can access with the `values` and `index` attributes.\n",
        "The `values` are simply a familiar NumPy array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KM6V_dvvzJDN",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "57de58ea-57bb-4ebc-f3bb-23d395cc0f24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.25, 0.5 , 0.75, 1.  ])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vkOM_5_zJDO"
      },
      "source": [
        "The `index` is an array-like object of type `pd.Index`, which we'll discuss in more detail momentarily:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVe7V1MrzJDO",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "ec22b6ef-d06b-4691-acd0-77a8c3e0684a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RangeIndex(start=0, stop=4, step=1)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kbKsr10zJDO"
      },
      "source": [
        "Like with a NumPy array, data can be accessed by the associated index via the familiar Python square-bracket notation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3u6XSztLzJDP",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "0a9c9b18-56bc-4db1-f7b9-81c539132966"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seerbQrezJDP",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "a4fae665-8796-4214-a8cc-6941d42a527b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    0.50\n",
              "2    0.75\n",
              "dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[1:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qlfr2a1jzJDP"
      },
      "source": [
        "As we will see, though, the Pandas `Series` is much more general and flexible than the one-dimensional NumPy array that it emulates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FcvEISrzJDP"
      },
      "source": [
        "### Series as Generalized NumPy Array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK7QZ87EzJDQ"
      },
      "source": [
        "From what we've seen so far, the `Series` object may appear to be basically interchangeable with a one-dimensional NumPy array.\n",
        "The essential difference is that while the NumPy array has an *implicitly defined* integer index used to access the values, the Pandas `Series` has an *explicitly defined* index associated with the values.\n",
        "\n",
        "This explicit index definition gives the `Series` object additional capabilities. For example, the index need not be an integer, but can consist of values of any desired type.\n",
        "So, if we wish, we can use strings as an index:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8E7Yb3cMzJDQ",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "90bc8e47-eab7-48f2-a3df-ced3841a1b20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "a    0.25\n",
              "b    0.50\n",
              "c    0.75\n",
              "d    1.00\n",
              "dtype: float64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
        "                 index=['a', 'b', 'c', 'd'])\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIpOj-PizJDQ"
      },
      "source": [
        "And the item access works as expected:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAdEnsQCzJDQ",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "af86891f-0410-4d4f-dcb0-9b9aa25c4cb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['b']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dwGsSZ1zJDQ"
      },
      "source": [
        "We can even use noncontiguous or nonsequential indices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avPu6xEEzJDQ",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "17f75d62-912f-4e38-d851-f23552116feb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    0.25\n",
              "5    0.50\n",
              "3    0.75\n",
              "7    1.00\n",
              "dtype: float64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
        "                 index=[2, 5, 3, 7])\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4xQvdTkzJDR",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "0511ada9-0b7e-4d6b-990d-83c09ba68b38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyOk3TUjzJDR"
      },
      "source": [
        "### Series as Specialized Dictionary\n",
        "\n",
        "In this way, you can think of a Pandas `Series` a bit like a specialization of a Python dictionary.\n",
        "A dictionary is a structure that maps arbitrary keys to a set of arbitrary values, and a `Series` is a structure that maps typed keys to a set of typed values.\n",
        "This typing is important: just as the type-specific compiled code behind a NumPy array makes it more efficient than a Python list for certain operations, the type information of a Pandas `Series` makes it more efficient than Python dictionaries for certain operations.\n",
        "\n",
        "The `Series`-as-dictionary analogy can be made even more clear by constructing a `Series` object directly from a Python dictionary, here the five most populous US states according to the 2020 census:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGBZXXVpzJDR",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "648fd150-c3d1-4a08-abaf-55ec68bb2395"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "California      39538223\n",
              "Texas           29145505\n",
              "Florida         21538187\n",
              "New York        20201249\n",
              "Pennsylvania    13002700\n",
              "dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "population_dict = {'California': 39538223, 'Texas': 29145505,\n",
        "                   'Florida': 21538187, 'New York': 20201249,\n",
        "                   'Pennsylvania': 13002700}\n",
        "population = pd.Series(population_dict)\n",
        "population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSWjpyKVzJDS"
      },
      "source": [
        "From here, typical dictionary-style item access can be performed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrR7opcfzJDS",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "1b930489-67db-49a2-dfdc-44b5084b72d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39538223"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "population['California']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fAG7IOwzJDU"
      },
      "source": [
        "## The Pandas DataFrame Object\n",
        "\n",
        "The next fundamental structure in Pandas is the `DataFrame`.\n",
        "Like the `Series` object discussed in the previous section, the `DataFrame` can be thought of either as a generalization of a NumPy array, or as a specialization of a Python dictionary.\n",
        "We'll now take a look at each of these perspectives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3A9DwD7zJDU"
      },
      "source": [
        "### DataFrame as Generalized NumPy Array\n",
        "If a `Series` is an analog of a one-dimensional array with explicit indices, a `DataFrame` is an analog of a two-dimensional array with explicit row and column indices.\n",
        "Just as you might think of a two-dimensional array as an ordered sequence of aligned one-dimensional columns, you can think of a `DataFrame` as a sequence of aligned `Series` objects.\n",
        "Here, by \"aligned\" we mean that they share the same index.\n",
        "\n",
        "To demonstrate this, let's first construct a new `Series` listing the area of each of the five states discussed in the previous section (in square kilometers):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxXlcA_XzJDU",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "d9cd9500-cc0b-4935-b1fb-8d2081b20ffb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "California      423967\n",
              "Texas           695662\n",
              "Florida         170312\n",
              "New York        141297\n",
              "Pennsylvania    119280\n",
              "dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "area_dict = {'California': 423967, 'Texas': 695662, 'Florida': 170312,\n",
        "             'New York': 141297, 'Pennsylvania': 119280}\n",
        "area = pd.Series(area_dict)\n",
        "area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfOVaYGJzJDU"
      },
      "source": [
        "Now that we have this along with the `population` Series from before, we can use a dictionary to construct a single two-dimensional object containing this information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQCY-HOHzJDV",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "a937ae70-6866-41b7-b14b-34ceb94859fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>population</th>\n",
              "      <th>area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>California</th>\n",
              "      <td>39538223</td>\n",
              "      <td>423967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Texas</th>\n",
              "      <td>29145505</td>\n",
              "      <td>695662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Florida</th>\n",
              "      <td>21538187</td>\n",
              "      <td>170312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>New York</th>\n",
              "      <td>20201249</td>\n",
              "      <td>141297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pennsylvania</th>\n",
              "      <td>13002700</td>\n",
              "      <td>119280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              population    area\n",
              "California      39538223  423967\n",
              "Texas           29145505  695662\n",
              "Florida         21538187  170312\n",
              "New York        20201249  141297\n",
              "Pennsylvania    13002700  119280"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "states = pd.DataFrame({'population': population,\n",
        "                       'area': area})\n",
        "states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMaD5nkGzJDV"
      },
      "source": [
        "Like the `Series` object, the `DataFrame` has an `index` attribute that gives access to the index labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vY1jKpaPzJDV",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "96d985bd-85fe-4579-ba68-d56830a105d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['California', 'Texas', 'Florida', 'New York', 'Pennsylvania'], dtype='object')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "states.index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OSRFkRXzJDV"
      },
      "source": [
        "Additionally, the `DataFrame` has a `columns` attribute, which is an `Index` object holding the column labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKaCZviHzJDV",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "c6c233cc-3937-42b0-8d15-f35943e16033"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['population', 'area'], dtype='object')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "states.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcImFiYjzJDW"
      },
      "source": [
        "Thus the `DataFrame` can be thought of as a generalization of a two-dimensional NumPy array, where both the rows and columns have a generalized index for accessing the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fF3CRQqqzheZ",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "9bb82657-f56a-4072-e285-89d39238bfe8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area</th>\n",
              "      <th>pop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>California</th>\n",
              "      <td>423967</td>\n",
              "      <td>39538223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Texas</th>\n",
              "      <td>695662</td>\n",
              "      <td>29145505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Florida</th>\n",
              "      <td>170312</td>\n",
              "      <td>21538187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>New York</th>\n",
              "      <td>141297</td>\n",
              "      <td>20201249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pennsylvania</th>\n",
              "      <td>119280</td>\n",
              "      <td>13002700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                area       pop\n",
              "California    423967  39538223\n",
              "Texas         695662  29145505\n",
              "Florida       170312  21538187\n",
              "New York      141297  20201249\n",
              "Pennsylvania  119280  13002700"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "area = pd.Series({'California': 423967, 'Texas': 695662,\n",
        "                  'Florida': 170312, 'New York': 141297,\n",
        "                  'Pennsylvania': 119280})\n",
        "pop = pd.Series({'California': 39538223, 'Texas': 29145505,\n",
        "                 'Florida': 21538187, 'New York': 20201249,\n",
        "                 'Pennsylvania': 13002700})\n",
        "data = pd.DataFrame({'area':area, 'pop':pop})\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUBxab2-zheZ"
      },
      "source": [
        "The individual `Series` that make up the columns of the `DataFrame` can be accessed via dictionary-style indexing of the column name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8WBeQcozheZ",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "7f8dee23-6d7e-4c4b-f072-7d42c529126c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "California      423967\n",
              "Texas           695662\n",
              "Florida         170312\n",
              "New York        141297\n",
              "Pennsylvania    119280\n",
              "Name: area, dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['area']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgAoOK4tzheZ"
      },
      "source": [
        "Equivalently, we can use attribute-style access with column names that are strings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aayKLmNszheZ",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "6084f0a1-5142-4277-d05d-151554d31dac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "California      423967\n",
              "Texas           695662\n",
              "Florida         170312\n",
              "New York        141297\n",
              "Pennsylvania    119280\n",
              "Name: area, dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3n4R6vR0DMH"
      },
      "source": [
        "# Handling Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbEV7ATe0DMI"
      },
      "source": [
        "The difference between data found in many tutorials and data in the real world is that real-world data is rarely clean and homogeneous.\n",
        "In particular, many interesting datasets will have some amount of data missing.\n",
        "To make matters even more complicated, different data sources may indicate missing data in different ways.\n",
        "\n",
        "In this chapter, we will discuss some general considerations for missing data, look at how Pandas chooses to represent it, and explore some built-in Pandas tools for handling missing data in Python.\n",
        "Here and throughout the book, I will refer to missing data in general as *null*, *NaN*, or *NA* values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lwtS0y80DMJ"
      },
      "source": [
        "## Trade-offs in Missing Data Conventions\n",
        "\n",
        "A number of approaches have been developed to track the presence of missing data in a table or `DataFrame`.\n",
        "Generally, they revolve around one of two strategies: using a *mask* that globally indicates missing values, or choosing a *sentinel value* that indicates a missing entry.\n",
        "\n",
        "In the masking approach, the mask might be an entirely separate Boolean array, or it might involve appropriation of one bit in the data representation to locally indicate the null status of a value.\n",
        "\n",
        "In the sentinel approach, the sentinel value could be some data-specific convention, such as indicating a missing integer value with –9999 or some rare bit pattern, or it could be a more global convention, such as indicating a missing floating-point value with `NaN` (Not a Number), a special value that is part of the IEEE floating-point specification.\n",
        "\n",
        "Neither of these approaches is without trade-offs. Use of a separate mask array requires allocation of an additional Boolean array, which adds overhead in both storage and computation. A sentinel value reduces the range of valid values that can be represented, and may require extra (often nonoptimized) logic in CPU and GPU arithmetic, because common special values like `NaN` are not available for all data types.\n",
        "\n",
        "As in most cases where no universally optimal choice exists, different languages and systems use different conventions.\n",
        "For example, the R language uses reserved bit patterns within each data type as sentinel values indicating missing data, while the SciDB system uses an extra byte attached to every cell to indicate an NA state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp92cGkV0DMK"
      },
      "source": [
        "## Missing Data in Pandas\n",
        "\n",
        "The way in which Pandas handles missing values is constrained by its reliance on the NumPy package, which does not have a built-in notion of NA values for non-floating-point data types.\n",
        "\n",
        "Perhaps Pandas could have followed R's lead in specifying bit patterns for each individual data type to indicate nullness, but this approach turns out to be rather unwieldy.\n",
        "While R has just 4 main data types, NumPy supports *far* more than this: for example, while R has a single integer type, NumPy supports 14 basic integer types once you account for available bit widths, signedness, and endianness of the encoding.\n",
        "Reserving a specific bit pattern in all available NumPy types would lead to an unwieldy amount of overhead in special-casing various operations for various types, likely even requiring a new fork of the NumPy package. Further, for the smaller data types (such as 8-bit integers), sacrificing a bit to use as a mask would significantly reduce the range of values it can represent.\n",
        "\n",
        "Because of these constraints and trade-offs, Pandas has two \"modes\" of storing and manipulating null values:\n",
        "\n",
        "- The default mode is to use a sentinel-based missing data scheme, with sentinel values `NaN` or `None` depending on the type of the data.\n",
        "- Alternatively, you can opt in to using the nullable data types (dtypes) Pandas provides (discussed later in this chapter), which results in the creation an accompanying mask array to track missing entries. These missing entries are then presented to the user as the special `pd.NA` value.\n",
        "\n",
        "In either case, the data operations and manipulations provided by the Pandas API will handle and propagate those missing entries in a predictable manner. But to develop some intuition into *why* these choices are made, let's dive quickly into the trade-offs inherent in `None`, `NaN`, and `NA`. As usual, we'll start by importing NumPy and Pandas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Z-Ecllt0DMK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKYkyTiA0DML"
      },
      "source": [
        "### None as a Sentinel Value\n",
        "\n",
        "For some data types, Pandas uses `None` as a sentinel value. `None` is a Python object, which means that any array containing `None` must have `dtype=object`—that is, it must be a sequence of Python objects.\n",
        "\n",
        "For example, observe what happens if you pass `None` to a NumPy array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuHc0mAU0DMM",
        "outputId": "7904f70d-bf0f-45cb-da88-8ccf7c765cda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, None, 2, 3], dtype=object)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vals1 = np.array([1, None, 2, 3])\n",
        "vals1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygp_wIbD0DMO"
      },
      "source": [
        "Further, because Python does not support arithmetic operations with `None`, aggregations like `sum` or `min` will generally lead to an error:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JLxSOhqQ0DMP",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "7df3f752-315d-4559-9f0c-922a6ec40bab"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'vals1' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvals1\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'vals1' is not defined"
          ]
        }
      ],
      "source": [
        "vals1.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9LOfOXt0DMP"
      },
      "source": [
        "For this reason, Pandas does not use `None` as a sentinel in its numerical arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUNj0BOy0DMQ"
      },
      "source": [
        "### NaN: Missing Numerical Data\n",
        "\n",
        "The other missing data sentinel, `NaN` is different; it is a special floating-point value recognized by all systems that use the standard IEEE floating-point representation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7pMXJdZ0DMQ",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "3d2edd68-2819-4017-c872-405753f3b935"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1., nan,  3.,  4.])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vals2 = np.array([1, np.nan, 3, 4])\n",
        "vals2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2Wx7Eiz0DMQ"
      },
      "source": [
        "Notice that NumPy chose a native floating-point type for this array: this means that unlike the object array from before, this array supports fast operations pushed into compiled code.\n",
        "Keep in mind that `NaN` is a bit like a data virus—it infects any other object it touches.\n",
        "Regardless of the operation, the result of arithmetic with `NaN` will be another `NaN`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0u4NyFw0DMQ",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "a035516a-7912-4c2e-a591-b5c65cc77577"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "1 + np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLFIjZUP0DMR",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "449531b4-725f-4632-df5a-6b0be52a33b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0 * np.nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArPQlymd0DMR"
      },
      "source": [
        "This means that aggregates over the values are well defined (i.e., they don't result in an error) but not always useful:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN0kCeph0DMR",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "8e266787-ae29-4390-dc20-0433f00310ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(nan, nan, nan)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vals2.sum(), vals2.min(), vals2.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py2PsfsL0DMS"
      },
      "source": [
        "That said, NumPy does provide ``NaN``-aware versions of aggregations that will ignore these missing values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4Fi-Fma0DMS",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "aeac5935-d36d-4c65-9400-8f0ec3284b07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8.0, 1.0, 4.0)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.nansum(vals2), np.nanmin(vals2), np.nanmax(vals2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KH6s5090DMS"
      },
      "source": [
        "The main downside of `NaN` is that it is specifically a floating-point value; there is no equivalent `NaN` value for integers, strings, or other types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtjoQRfg0DMT"
      },
      "source": [
        "### NaN and None in Pandas\n",
        "\n",
        "`NaN` and `None` both have their place, and Pandas is built to handle the two of them nearly interchangeably, converting between them where appropriate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sncvMi8F0DMT",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "07d2bb3e-a349-49a3-9773-32585abf7e69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1.0\n",
              "1    NaN\n",
              "2    2.0\n",
              "3    NaN\n",
              "dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.Series([1, np.nan, 2, None])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GffQ0GNR0DMT"
      },
      "source": [
        "For types that don't have an available sentinel value, Pandas automatically typecasts when NA values are present.\n",
        "For example, if we set a value in an integer array to ``np.nan``, it will automatically be upcast to a floating-point type to accommodate the NA:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ITAkr0f0DMT",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "f472c306-09e6-4814-9d22-03a9fe6f43d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    0\n",
              "1    1\n",
              "dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = pd.Series(range(2), dtype=int)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riOrlo_r0DMT",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "cb833407-0d42-4fcc-f61f-721036bc1fc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    NaN\n",
              "1    1.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0] = None\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4VatZZF0DMU"
      },
      "source": [
        "Notice that in addition to casting the integer array to floating point, Pandas automatically converts the ``None`` to a ``NaN`` value.\n",
        "\n",
        "While this type of magic may feel a bit hackish compared to the more unified approach to NA values in domain-specific languages like R, the Pandas sentinel/casting approach works quite well in practice and in my experience only rarely causes issues.\n",
        "\n",
        "The following table lists the upcasting conventions in Pandas when NA values are introduced:\n",
        "\n",
        "|Typeclass     | Conversion when storing NAs | NA sentinel value      |\n",
        "|--------------|-----------------------------|------------------------|\n",
        "| ``floating`` | No change                   | ``np.nan``             |\n",
        "| ``object``   | No change                   | ``None`` or ``np.nan`` |\n",
        "| ``integer``  | Cast to ``float64``         | ``np.nan``             |\n",
        "| ``boolean``  | Cast to ``object``          | ``None`` or ``np.nan`` |\n",
        "\n",
        "Keep in mind that in Pandas, string data is always stored with an ``object`` dtype."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkmuZe3p0DMU"
      },
      "source": [
        "## Pandas Nullable Dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRiQBiQc0DMU"
      },
      "source": [
        "In early versions of Pandas, `NaN` and `None` as sentinel values were the only missing data representations available. The primary difficulty this introduced was with regard to the implicit type casting: for example, there was no way to represent a true integer array with missing data.\n",
        "\n",
        "To address this difficulty, Pandas later added *nullable dtypes*, which are distinguished from regular dtypes by capitalization of their names (e.g., `pd.Int32` versus `np.int32`). For backward compatibility, these nullable dtypes are only used if specifically requested.\n",
        "\n",
        "For example, here is a `Series` of integers with missing data, created from a list containing all three available markers of missing data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy1a3xQY0DMU",
        "outputId": "22f5b32a-4823-4686-bb31-23bd718c3b6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       1\n",
              "1    <NA>\n",
              "2       2\n",
              "3    <NA>\n",
              "4    <NA>\n",
              "dtype: Int32"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.Series([1, np.nan, 2, None, pd.NA], dtype='Int32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVOdX6nS0DMU"
      },
      "source": [
        "This representation can be used interchangeably with the others in all the operations explored through the rest of this chapter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDyOBoUG0DMV"
      },
      "source": [
        "## Operating on Null Values\n",
        "\n",
        "As we have seen, Pandas treats `None`, `NaN`, and `NA` as essentially interchangeable for indicating missing or null values.\n",
        "To facilitate this convention, Pandas provides several methods for detecting, removing, and replacing null values in Pandas data structures.\n",
        "They are:\n",
        "\n",
        "- ``isnull``: Generates a Boolean mask indicating missing values\n",
        "- ``notnull``: Opposite of ``isnull``\n",
        "- ``dropna``: Returns a filtered version of the data\n",
        "- ``fillna``: Returns a copy of the data with missing values filled or imputed\n",
        "\n",
        "We will conclude this chapter with a brief exploration and demonstration of these routines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIbJcLO70DMV"
      },
      "source": [
        "### Detecting Null Values\n",
        "Pandas data structures have two useful methods for detecting null data: `isnull` and `notnull`.\n",
        "Either one will return a Boolean mask over the data. For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZN0InsQ0DMV",
        "tags": []
      },
      "outputs": [],
      "source": [
        "data = pd.Series([1, np.nan, 'hello', None])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpZY4WgL0DMV",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "6e715243-6cfd-4b5c-f3db-7ac1e65a1ce2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    False\n",
              "1     True\n",
              "2    False\n",
              "3     True\n",
              "dtype: bool"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.isnull()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ObEeBoi0DMV"
      },
      "source": [
        "As mentioned in [Data Indexing and Selection](03.02-Data-Indexing-and-Selection.ipynb), Boolean masks can be used directly as a `Series` or `DataFrame` index:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRFHOQV70DMV",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "2886e4e6-a743-4044-e8f5-fc1d2d7bb33f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        1\n",
              "2    hello\n",
              "dtype: object"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[data.notnull()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAMcMpXw0DMW"
      },
      "source": [
        "The `isnull()` and `notnull()` methods produce similar Boolean results for ``DataFrame`` objects."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twourd6L0DMW"
      },
      "source": [
        "### Dropping Null Values\n",
        "\n",
        "In addition to these masking methods, there are the convenience methods `dropna`\n",
        "(which removes NA values) and `fillna` (which fills in NA values). For a `Series`,\n",
        "the result is straightforward:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jV5co0r0DMW",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "1ad42e56-8376-4779-f081-0a2365fa4690"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        1\n",
              "2    hello\n",
              "dtype: object"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0gCIPlW0DMX"
      },
      "source": [
        "For a ``DataFrame``, there are more options.\n",
        "Consider the following ``DataFrame``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7m6Nyf9c0DMX",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "5703f18e-d545-478d-deca-c7b8dd7ebc36"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1  2\n",
              "0  1.0  NaN  2\n",
              "1  2.0  3.0  5\n",
              "2  NaN  4.0  6"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame([[1,      np.nan, 2],\n",
        "                   [2,      3,      5],\n",
        "                   [np.nan, 4,      6]])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v_B80Pw0DMX"
      },
      "source": [
        "We cannot drop single values from a `DataFrame`; we can only drop entire rows or columns.\n",
        "Depending on the application, you might want one or the other, so `dropna` includes a number of options for a `DataFrame`.\n",
        "\n",
        "By default, `dropna` will drop all rows in which *any* null value is present:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rc1LAJm80DMX",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "9bfd1d4d-aa35-4df4-bbba-57ad2b5c8c87"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1  2\n",
              "1  2.0  3.0  5"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e5SATQC0DMY"
      },
      "source": [
        "Alternatively, you can drop NA values along a different axis. Using `axis=1` or `axis='columns'` drops all columns containing a null value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEe0aOw-0DMY",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "18bf1862-8254-4865-c7bb-8114d433efc7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   2\n",
              "0  2\n",
              "1  5\n",
              "2  6"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dropna(axis='columns')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwUQIv540DMY"
      },
      "source": [
        "But this drops some good data as well; you might rather be interested in dropping rows or columns with *all* NA values, or a majority of NA values.\n",
        "This can be specified through the `how` or `thresh` parameters, which allow fine control of the number of nulls to allow through.\n",
        "\n",
        "The default is `how='any'`, such that any row or column containing a null value will be dropped.\n",
        "You can also specify `how='all'`, which will only drop rows/columns that contain *all* null values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7XsdzYj0DMY",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "b3f60881-0584-4638-835d-c4094edec37a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1  2   3\n",
              "0  1.0  NaN  2 NaN\n",
              "1  2.0  3.0  5 NaN\n",
              "2  NaN  4.0  6 NaN"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[3] = np.nan\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrRO8Kb-0DMY",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "f8ba701e-fded-4d1e-84e2-edf85932a649"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1  2\n",
              "0  1.0  NaN  2\n",
              "1  2.0  3.0  5\n",
              "2  NaN  4.0  6"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dropna(axis='columns', how='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rRhyVp30DMZ"
      },
      "source": [
        "### Filling Null Values\n",
        "\n",
        "Sometimes rather than dropping NA values, you'd like to replace them with a valid value.\n",
        "This value might be a single number like zero, or it might be some sort of imputation or interpolation from the good values.\n",
        "You could do this in-place using the `isnull` method as a mask, but because it is such a common operation Pandas provides the `fillna` method, which returns a copy of the array with the null values replaced.\n",
        "\n",
        "Consider the following `Series`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulAOr_5f0DMa",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "2c267f98-14df-4bac-9467-fe8577b5d5aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "a       1\n",
              "b    <NA>\n",
              "c       2\n",
              "d    <NA>\n",
              "e       3\n",
              "dtype: Int32"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'), dtype='Int32')\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc9tFB5p0DMa"
      },
      "source": [
        "We can fill NA entries with a single value, such as zero:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mUlBVhY0DMa",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "6e74399e-67c2-4aa8-f612-34535054c4cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "a    1\n",
              "b    0\n",
              "c    2\n",
              "d    0\n",
              "e    3\n",
              "dtype: Int32"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgpYyGeH0DMa"
      },
      "source": [
        "We can specify a forward fill to propagate the previous value forward:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpVOl88q0DMb",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "c03e3316-fce1-41f2-9bfe-ca9cd654a338"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "a    1\n",
              "b    1\n",
              "c    2\n",
              "d    2\n",
              "e    3\n",
              "dtype: Int32"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# forward fill\n",
        "data.fillna(method='ffill')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Iyvzd3_0DMb"
      },
      "source": [
        "Or we can specify a backward fill to propagate the next values backward:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_AvBw3C0DMb",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "63d764ef-7aed-4172-f675-98c8b3529558"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "a    1\n",
              "b    2\n",
              "c    2\n",
              "d    3\n",
              "e    3\n",
              "dtype: Int32"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# back fill\n",
        "data.fillna(method='bfill')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAkHHV4u0DMc"
      },
      "source": [
        "In the case of a `DataFrame`, the options are similar, but we can also specify an `axis` along which the fills should take place:"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
